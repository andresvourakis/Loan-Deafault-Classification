{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and EDA\n",
    "\n",
    "\n",
    "**Overview:** This notebook goes through data cleaning and exploratory data analysis in order to prepare for model building.\n",
    "\n",
    "Specifically, we'll be walking through:\n",
    "\n",
    "1. **Getting the data:** In this case, the data is stored in an SQL table\n",
    "2. **Exploratory Data Analysis (EDA):** Visualizing the data to understand the distribution and correlation of different features.\n",
    "3. **Data Cleaning:** Basic pre-processing techniques\n",
    "\n",
    "The output of this notebook will be clean, organized data stored as a serialized (pickled) dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "Build a predictive model that assigns default probabilities to loan applications and it is similar to what our credit modeling team is doing. Predict the probability that a customer is going to default (target=1) or not (target=0).\n",
    "\n",
    "**Assumption:** The dataset provided contains credit and loan information about users and whether they have defaulted or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "conn = psycopg2.connect(\"dbname=sample user=hiring password=g~+oc2ABz#-GE+u%pQ3Z host=anyfin-work-sample.cn2fqd2vd4bc.eu-west-1.rds.amazonaws.com\")\n",
    "\n",
    "# Activation connection cursor\n",
    "#cur = conn.cursor()\n",
    "\n",
    "# Run query and display\n",
    "#cur.execute(\"SELECT * FROM creditdataset\")\n",
    "#rows = cur.fetchall()\n",
    "#rows\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM creditdataset\", conn)\n",
    "\n",
    "# Close connections\n",
    "#cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Since ultimately, the goal will be to pick the best features to build the predictive model, it is important to learn as much as possible about the data. In my case, I don't have the time, or resources to learn what each one of the columns truly represent. I will limit my exploration of the data to the columns that make the most sense and proceed with my prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_type = df[\"loan_type\"].value_counts()\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.barplot(loan_type.index, loan_type.values)\n",
    "plt.title('Distribution of Loan Types')\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Type', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** Most popular loan type is \"pos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_city = df[\"big_city\"].value_counts()\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.barplot(big_city.index, big_city.values)\n",
    "plt.title('Distribution of people who live in Big City')\n",
    "plt.ylabel('Number of People', fontsize=12)\n",
    "plt.xlabel('Big City', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"target\"].map({0:\"No Default\", 1:\"Default\"}).value_counts()\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.barplot(target.index, target.values)\n",
    "plt.title('Dafault vs No Default')\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Type', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** As we can see, most people on the dataset don't default, this means that the data is unbalanced and training on this dataset might not give us the best predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spouse = df[\"target\"].map({0:\"Single\", 1:\"Married\"}).value_counts()\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.barplot(spouse.index, spouse.values)\n",
    "plt.title('Distribution of Married vs Single clients')\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Type', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obervations:** The majority of people who applied for a loan are not married (no spouse). It would be interesting to see its correlation with the \"external_score\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 5 columns of interest:**\n",
    "These are some of the columns that could have useful information to make a prediction. The goal is to explore them first, and then focus on the rest of the columns.\n",
    "\n",
    "1. target\n",
    "2. loan_type\n",
    "3. income_gross\n",
    "4. customer_age\n",
    "5. credit_approved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**creditdataset:** This data set contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.swarmplot(x=\"has_spouce\", y=\"external_score\", data=df)\n",
    "plt.title(\"Spouse and External Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External Score and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.swarmplot(x=\"target\", y=\"external_score\", data=df)\n",
    "plt.title(\"Target and External Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"external_score\", \"target\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** As we can see from the plot, there seems to be a correlation between the \"external_score\" of the client and whether they defaulted or not. Calculating the correlation score confirms our observations. It looks like any client with a \"external_score\" above 40 defaults, which means that having a lower score is better than having a high one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.swarmplot(x=\"big_city\", y=\"external_score\", data=df)\n",
    "plt.title(\"Big City and External Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** This seems to tell us that the majority of people who don't live in the big city have a \"external_score\" less than 40, which means that they won't default. Almost every client who lives in the big city has a \"external_score\" less than 40. There seems to be correlation between living in the big city and not defaulting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"big_city\", \"target\"])[\"target\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.swarmplot(x=\"target\", y=\"income_gross\", data=df)\n",
    "plt.title(\"Target and Income Gross\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"income_gross\", \"target\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** There doesn't seem to be any strong correlation between how much a client makes and weather they default or not. Although the majority of people with a lower gross income does not default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping columns\n",
    "Removing columns that don't seem to provide much useful information when predicting loan default. These are columns that meet any of the following criteria:\n",
    "\n",
    "1. High percentage of missing values\n",
    "2. Pairwise correlation (Redundant columns)\n",
    "3. Low variation in the values\n",
    "4. Non informative (i.e. id)\n",
    "\n",
    "By dropping unsuful columns, we will make it computationally easier to do better feature selection during the model building process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_colums = [\"id\", \"email_domain\", \"contact_channel\", \"debt_requests_count\", \"housing_rent\", \"housing_rent\", \"credit_used_account\", \"customer_postal\", \"lender_id\", \"inquiries_count_12m\", \"loan_fee\", \"loan_interest\", \"hour_1\", \"day\", \"housing_base_cost\"]\n",
    "clean_df = df.drop(columns=drop_colums)\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.dropna(how=\"any\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_pickle(\"clean_df.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
